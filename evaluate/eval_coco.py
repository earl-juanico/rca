"""
(c)2024, earl-juanico
This script extracts the detections (aka predictions)
from the VLM known as LLaVA. 
"""
import re
import json
import ast
import cv2

# load the coco synset categories from file "synset.jsonl"
with open('./coco_synset.jsonl','r') as f:
    COCO_SYNSET_CATEGORIES = [json.loads(line) for line in f]

ROOT_DIR = '/data/vlm/playground/data/'
coco_data_json = ROOT_DIR+'/coco/annotations/instances_val2017.json'
coco_caps_json = ROOT_DIR+'coco/annotations/captions_val2017.json'

lvis_to_coco_map = './coco_to_synset.json'
lvis_data_json = ROOT_DIR+'lvis_v1/annotations/lvis_v1_val.json'


# Load the COCO dataset annotations file
with open(coco_data_json, 'r') as f:
    coco_data = json.load(f)
with open(coco_caps_json, 'r') as f:
    coco_caps = json.load(f)
with open(lvis_to_coco_map,'r') as f:
    synset_lvis = json.load(f)
with open(lvis_data_json, 'r') as f:
    lvis_data = json.load(f)

objects = coco_data['annotations']
images = coco_data['images']
cats = coco_data['categories']
lats = lvis_data['categories']
captions = coco_caps['annotations']

def get_predictions_from_llava(text: str) -> list:
    # For improvement
    # Use a regex string matching function such as in LangChain library
    # The 'text' input is a query to the LLaVA model
    pattern1 = r'\[(\d+\.\d+), (\d+\.\d+), (\d+\.\d+), (\d+\.\d+)\]'
    pattern2 = r'\((\d+\.\d+), (\d+\.\d+), (\d+\.\d+), (\d+\.\d+)\)'
    
    matches1 = re.findall(pattern1, text)
    matches2 = re.findall(pattern2, text)
    
    numbers1 = [[float(match) for match in match_tuple] for match_tuple in matches1]
    numbers2 = [[float(match) for match in match_tuple] for match_tuple in matches2]
    
    # Convert the format of numbers2 to the format of numbers1
    numbers2 = [f'[{", ".join(map(str, match_tuple))}]' for match_tuple in numbers2]
    numbers2 = [ast.literal_eval(match_tuple) for match_tuple in numbers2]
    
    predictions = numbers1 + numbers2
    if not predictions:
        #predictions = [[0.0, 0.0, 1.0, 1.0]]  # this is a bug
        predictions = [[0.0, 0.0, 0.0, 0.0]]  # this is a bug
    return predictions


def convert_json_to_jsonl(json_filename: str)-> str:
    with open(json_filename, 'r') as f:  # The json file may be generated by another script
        json_data = json.load(f)
    jsonl_data = []
    for item in json_data:
        jsonl_data.append(json.dumps(item))
    jsonl_filename = json_filename.replace('.json','.jsonl')
    with open(jsonl_filename, 'w') as f:
        for item in jsonl_data:
            f.write(item + '\n')
    return jsonl_filename    # The file with this name will be used by the evaluation script

def object_type_in_image(image_id: int, cat_id: int) -> list:
    # Extracts the bounding boxes of the specified object type in the specified image
    object_bbox = []
    H = next((image['height'] for image in images if image['id']==image_id),None)
    W = next((image['width'] for image in images if image['id']==image_id),None)
    for object in objects:
        if object['image_id'] == image_id and object['category_id'] == cat_id:
            x,y,w,h = object['bbox']
            object_bbox.append(f'[{x/W:.2f}, {y/H:.2f}, {(x+w)/W:.2f}, {(y+h)/H:.2f}]')
    return object_bbox

'''
def draw_bboxes(image_path: str, cls: list, bbox_gt: list, bbox_pt: list, TP:int, FP:int, IoU:list, save_path:str):
    # Load the image and get dimensions
    image = cv2.imread(image_path)
    H, W, _ = image.shape

    # Handle empty cls list
    if not cls:
        category = "unknown"
        print(f"Warning: 'cls' is empty for image {image_path}. Using category 'unknown'.")
    else:
        category = cls[0]

    # Write text at the top center of the image
    text = category
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.7
    font_color = (255, 0, 0)  # blue
    thickness = 2
    text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)
    text_x = (W - text_size[0]) // 2
    text_y = text_size[1] + 20  # 20 pixels offset from the top

    # Write number of true and false positives in the image below the category
    tp_text = f"TP: {TP}"
    fp_text = f"FP: {FP}"

    image_width = W
    (tw1, th1), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
    (tw2, th2), _ = cv2.getTextSize(tp_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
    (tw3, th3), _ = cv2.getTextSize(fp_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
    (text_width, text_height) = (max(tw1, tw2, tw3), th1 + th2 + th3)

    # Position the text in the upper right corner
    text_x = image_width - text_width
    text_y = text_height

    image = cv2.rectangle(image,(text_x,text_y-15),(text_x+text_width+2,text_y+text_height+15),(0,255,255),cv2.FILLED)
    image = cv2.putText(image, text, (text_x, text_y), font, font_scale, font_color, thickness)
    image = cv2.putText(image, tp_text, (text_x, text_y + 30), font, font_scale, font_color, thickness)
    image = cv2.putText(image, fp_text, (text_x, text_y + 60), font, font_scale, font_color, thickness)

    # Draw the ground truth bounding boxes
    for bbox in bbox_gt:
        x1, y1, x2, y2 = ast.literal_eval(bbox)
        x1, y1, x2, y2 = int(x1*W), int(y1*H), int(x2*W), int(y2*H)
        image = cv2.rectangle(image, (x1,y1), (x2,y2), (0,255,0), 1)  # green with thickness 2

    # Draw the predicted bounding boxes and print IoU values
    for i, bbox in enumerate(bbox_pt):
        x1, y1, x2, y2 = ast.literal_eval(bbox)
        x1, y1, x2, y2 = int(x1*W), int(y1*H), int(x2*W), int(y2*H)
        image = cv2.rectangle(image, (x1,y1), (x2,y2), (0,0,255), 1)  # red with thickness 2
        iou_text = f"IoU: {IoU[i]:.2f}"
        (text_width, text_height), _ = cv2.getTextSize(iou_text, cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.5, 1)
        box_coords = ((x1, y1+10), (x1 + text_width + 2, y1 + 10 - text_height - 2))
        image = cv2.rectangle(image, box_coords[0], box_coords[1], (0,255,255), cv2.FILLED)  # yellow rectangle
        image = cv2.putText(img=image, 
                            text=iou_text, 
                            org=box_coords[0], 
                            fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL, 
                            fontScale=0.5, 
                            color=(0,0,255), 
                            thickness=1)  # red

    # Save the image with bounding boxes to the specified save path
    cv2.imwrite(save_path, image)
'''
def draw_bboxes(image_path: str, cls: list, bbox_gt: list, bbox_pt: list, TP:int, FP:int, IoU:list, save_path:str):
    # Load the image and get dimensions
    image = cv2.imread(image_path)
    H, W, _ = image.shape

    # Handle empty cls list
    if not cls:
        category = "unknown"
        print(f"Warning: 'cls' is empty for image {image_path}. Using category 'unknown'.")
    else:
        category = cls[0]

    # Write text at the top center of the image
    text = category
    # Use Arial font if available, otherwise fallback to Hershey Simplex
    try:
        font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"  # Arial alternative on Linux
        arial_font = cv2.FONT_HERSHEY_SIMPLEX
        font = arial_font
    except:
        font = cv2.FONT_HERSHEY_SIMPLEX

    font_scale = 0.9
    font_color = (255, 0, 0)  # blue
    thickness = 2
    text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)
    text_x = (W - text_size[0]) // 2
    text_y = text_size[1] + 20  # 20 pixels offset from the top

    # Write number of true and false positives in the image below the category
    tp_text = f"TP: {TP}"
    fp_text = f"FP: {FP}"

    image_width = W
    (tw1, th1), _ = cv2.getTextSize(text, font, font_scale, thickness)
    (tw2, th2), _ = cv2.getTextSize(tp_text, font, font_scale, thickness)
    (tw3, th3), _ = cv2.getTextSize(fp_text, font, font_scale, thickness)
    (text_width, text_height) = (max(tw1, tw2, tw3), th1 + th2 + th3)

    # Position the text in the upper right corner
    text_x = image_width - text_width
    text_y = text_height

    image = cv2.rectangle(image,(text_x,text_y-15),(text_x+text_width+2,text_y+text_height+15),(0,255,255),cv2.FILLED)
    image = cv2.putText(image, text, (text_x, text_y), font, font_scale, font_color, thickness)
    image = cv2.putText(image, tp_text, (text_x, text_y + 30), font, font_scale, font_color, thickness)
    image = cv2.putText(image, fp_text, (text_x, text_y + 60), font, font_scale, font_color, thickness)

    # Draw the ground truth bounding boxes (thick solid green)
    for bbox in bbox_gt:
        x1, y1, x2, y2 = ast.literal_eval(bbox)
        x1, y1, x2, y2 = int(x1*W), int(y1*H), int(x2*W), int(y2*H)
        image = cv2.rectangle(image, (x1,y1), (x2,y2), (0,255,0), 3)  # thick solid green

    # Draw the predicted bounding boxes and print IoU values
    for i, bbox in enumerate(bbox_pt):
        x1, y1, x2, y2 = ast.literal_eval(bbox)
        x1, y1, x2, y2 = int(x1*W), int(y1*H), int(x2*W), int(y2*H)
        # Draw thick dashed red rectangle
        dash_length = 10
        gap_length = 6
        # Top edge
        for x in range(x1, x2, dash_length + gap_length):
            x_end = min(x + dash_length, x2)
            image = cv2.line(image, (x, y1), (x_end, y1), (0,0,255), 3)
        # Bottom edge
        for x in range(x1, x2, dash_length + gap_length):
            x_end = min(x + dash_length, x2)
            image = cv2.line(image, (x, y2), (x_end, y2), (0,0,255), 3)
        # Left edge
        for y in range(y1, y2, dash_length + gap_length):
            y_end = min(y + dash_length, y2)
            image = cv2.line(image, (x1, y), (x1, y_end), (0,0,255), 3)
        # Right edge
        for y in range(y1, y2, dash_length + gap_length):
            y_end = min(y + dash_length, y2)
            image = cv2.line(image, (x2, y), (x2, y_end), (0,0,255), 3)

        # IoU printing
        iou_text = f"IoU: {IoU[i]:.2f}"
        (text_width, text_height), _ = cv2.getTextSize(iou_text, font, 0.8, 1)
        box_coords = ((x1, y1+10), (x1 + text_width + 2, y1 + 10 - text_height - 2))
        image = cv2.rectangle(image, box_coords[0], box_coords[1], (255,0,0), cv2.FILLED)  # yellow rectangle
        image = cv2.putText(img=image, 
                            text=iou_text, 
                            org=box_coords[0], 
                            fontFace=font, 
                            fontScale=0.8, 
                            color=(0,255,255), 
                            thickness=2)  # yellow text on blue background

    # Save the image with bounding boxes to the specified save path
    cv2.imwrite(save_path, image)


import statistics
def evaluate_coco(coco_gt_file: str, llava_answers_file: str):
    ground_truth=[]
    grounds=[]
    cls=[]
    with open(coco_gt_file,'r') as f:
        lines = f.readlines()
        grounds = [json.loads(line).get('answers', '') for line in lines]
        cls = [json.loads(line).get('class','') for line in lines]
    for gt in grounds:
        ground_truth.append([ast.literal_eval(g) for g in gt])
   
    predictions=[]
    with open(llava_answers_file,'r') as f:
        lines = f.readlines()
        predictions = [[(bbox, round((bbox[2]-bbox[0])*(bbox[3]-bbox[1]), 4)) for bbox in get_predictions_from_llava(json.loads(line).get('text', ''))] for line in lines]
        #print(f'Predicted boxes with areas: {predictions}')
    '''
    detections=[]
    confs=[]
    with open(llava_answers_file,'r') as f:
        lines = f.readlines()
        predictions = [get_predictions_from_llava(json.loads(line).get('text', '')) for line in lines]
        # predictions must be in bbox list format after running extract_bbox_from_answer.py beforehand
        #  the confidence proxy can be calculated from the bbox area
        print(f'Predicted boxes: {predictions}')
    for pred in predictions:
        for bbox in pred:
            x1,y1,x2,y2=tuple(bbox)
            area = (x2-x1)*(y2-y1)
            detections.append((bbox,round(area,4)))
            confs.append(area)
    #predictions = detections
    # debug 
    print(f'Transformed predictions: {detections}')  # debug
    print(f'Conf Maximum: {max(confs)}')
    print(f'Conf Minimum: {min(confs)}')
    print(f'Conf Ave: {statistics.mean(confs)}')
    print(f'Conf Median: {statistics.median(confs)}')
    print(f'Conf Mode: {statistics.mode(confs)}')
    print(f'Conf Variance: {statistics.variance(confs)}')
    
    print(f'Number of gt prompts answered: {len(ground_truth)}') #debug
    print(f'Number of pred prompts answered: {len(predictions)}') #debug
    #assert(len(ground_truth)==len(predictions))
    '''
    return cls, ground_truth, predictions