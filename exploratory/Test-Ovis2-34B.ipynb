{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb0910e",
   "metadata": {},
   "source": [
    "## Ovis2 34B\n",
    "\n",
    "* From AIDC-AI\n",
    "* Ranked #4 in OpenCompass multimodal academic leaderboard for open-source models (https://rank.opencompass.org.cn/leaderboard-multimodal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a71b540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.embed_tokens.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:   6%|▌         | 1/17 [00:00<00:06,  2.33it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  12%|█▏        | 2/17 [00:00<00:06,  2.33it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  18%|█▊        | 3/17 [00:01<00:06,  2.28it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  24%|██▎       | 4/17 [00:01<00:05,  2.54it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  29%|██▉       | 5/17 [00:01<00:03,  3.17it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  35%|███▌      | 6/17 [00:01<00:02,  3.72it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  41%|████      | 7/17 [00:02<00:02,  4.19it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  47%|████▋     | 8/17 [00:02<00:02,  4.11it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.32.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.33.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  53%|█████▎    | 9/17 [00:02<00:01,  4.38it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.34.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.35.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.36.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.37.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  59%|█████▉    | 10/17 [00:02<00:01,  4.18it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.38.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.39.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.40.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.41.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  65%|██████▍   | 11/17 [00:03<00:01,  4.18it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.42.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.43.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.44.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.45.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  71%|███████   | 12/17 [00:03<00:01,  4.05it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.46.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.47.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.48.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.49.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  76%|███████▋  | 13/17 [00:03<00:01,  3.98it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.50.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.51.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.52.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.53.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  82%|████████▏ | 14/17 [00:03<00:00,  4.38it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.54.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.55.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.56.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.57.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  88%|████████▊ | 15/17 [00:04<00:00,  4.51it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.58.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.59.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.60.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.61.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  94%|█████████▍| 16/17 [00:04<00:00,  4.61it/s]/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.62.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.63.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.norm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/data/students/earl/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for lm_head.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 17/17 [00:04<00:00,  3.78it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 15/15 [00:23<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# conda activate rca\n",
    "'''\n",
    "Ovis2-34B \n",
    "'''\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# load model\n",
    "model_path = '/data/students/earl/llava-dissector/Ovis2-34B'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             multimodal_max_length=32768,\n",
    "                                             trust_remote_code=True,\n",
    "                                             device_map='auto') # distribute the load across multiple available GPUs\n",
    "text_tokenizer = model.get_text_tokenizer()\n",
    "visual_tokenizer = model.get_visual_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638c931",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m     36\u001b[0m     gen_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     37\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     38\u001b[0m         do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     )\n\u001b[0;32m---> 47\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     48\u001b[0m     output \u001b[38;5;241m=\u001b[39m text_tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Ovis2-34B/modeling_ovis.py:683\u001b[0m, in \u001b[0;36mCustomOvis.generate\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    682\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m--> 683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/transformers/generation/utils.py:2252\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2245\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2246\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2247\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2248\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2249\u001b[0m     )\n\u001b[1;32m   2251\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2253\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2265\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2266\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2272\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/transformers/generation/utils.py:3251\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 3251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3252\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Ovis2-34B/modeling_ovis.py:615\u001b[0m, in \u001b[0;36mCustomQwen2ForCausalLM.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    614\u001b[0m     output_hidden_states \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 615\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodify_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    617\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:1165\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1162\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1165\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:895\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    883\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    884\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    885\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m         position_embeddings,\n\u001b[1;32m    893\u001b[0m     )\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:620\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m        into the model\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    618\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    623\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    624\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    625\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    632\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/rca/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:78\u001b[0m, in \u001b[0;36mQwen2RMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m     77\u001b[0m     input_dtype \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m---> 78\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "cls = \"baseball helmet\"\n",
    "\n",
    "url = \"https://farm3.staticflickr.com/2402/2480652763_e6b62303ee_z.jpg\"\n",
    "response = requests.get(url)\n",
    "orig_img = Image.open(io.BytesIO(response.content)).convert('RGB')\n",
    "orig_img_np = np.array(orig_img)  # HWC, RGB, uint8\n",
    "img = orig_img_np #cv2.cvtColor(orig_img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "text = f'Give the normalized bounding box coordinates in the format [x1, y1, x2, y2] of all instances of {cls} in the image'\n",
    "#text = f'Give the bounding box coordinates of all instances of {cls} in the image.'\n",
    "#text = f'Describe the image in detail.'\n",
    "query = f'<image>\\n{text}'\n",
    "images = [orig_img]\n",
    "max_partition = 9\n",
    "\n",
    "model.threshold = -1.1\n",
    "\n",
    "# format conversation\n",
    "prompt, input_ids, pixel_values = model.preprocess_inputs(query, images, max_partition=max_partition)\n",
    "attention_mask = torch.ne(input_ids, text_tokenizer.pad_token_id)\n",
    "input_ids = input_ids.unsqueeze(0).to(device=model.device)\n",
    "attention_mask = attention_mask.unsqueeze(0).to(device=model.device)\n",
    "if pixel_values is not None:\n",
    "    pixel_values = pixel_values.to(dtype=visual_tokenizer.dtype, device=visual_tokenizer.device)\n",
    "pixel_values = [pixel_values]\n",
    "\n",
    "# generate output\n",
    "with torch.inference_mode():\n",
    "    gen_kwargs = dict(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        top_p=None,\n",
    "        top_k=None,\n",
    "        temperature=None,\n",
    "        repetition_penalty=None,\n",
    "        eos_token_id=model.generation_config.eos_token_id,\n",
    "        pad_token_id=text_tokenizer.pad_token_id,\n",
    "        use_cache=True\n",
    "    )\n",
    "    output_ids = model.generate(\n",
    "        input_ids, \n",
    "        pixel_values=pixel_values, \n",
    "        attention_mask=attention_mask, \n",
    "        **gen_kwargs\n",
    "    )[0]\n",
    "    output = text_tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    print(f'Output:\\n{output}')\n",
    "    \n",
    "    \n",
    "img_width, img_height = img.shape[1], img.shape[0]\n",
    "print(f'Image Width: {img_width}, Image Height: {img_height}')\n",
    "\n",
    "# Using cv2 to draw bounding boxes on the image\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pattern = r'\\[\\s*([\\d.]+)\\s*,\\s*([\\d.]+)\\s*,\\s*([\\d.]+)\\s*,\\s*([\\d.]+)\\s*\\]'\n",
    "pattern = r'(?:[\\[\\(]\\s*([\\d.]+)\\s*,\\s*([\\d.]+)\\s*,\\s*([\\d.]+)\\s*,\\s*([\\d.]+)\\s*[\\]\\)])|(?:<box>\\s*([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s*</box>)'\n",
    "matches = re.findall(pattern, output)\n",
    "bounding_boxes = [[float(coord) for coord in match] for match in matches]\n",
    "print(\"Bounding boxes:\", bounding_boxes)\n",
    "\n",
    "# Visualize using cv2\n",
    "import cv2\n",
    "import numpy as np\n",
    "img_cv = img #np.array(img)\n",
    "for box in bounding_boxes:\n",
    "    x1, y1, x2, y2 = box\n",
    "    # convert these normalized coordinates to pixel values\n",
    "    h, w, _ = img_cv.shape\n",
    "    x1 = int(x1 * w)\n",
    "    y1 = int(y1 * h)\n",
    "    x2 = int(x2 * w)\n",
    "    y2 = int(y2 * h)\n",
    "    # Draw the bounding box and label on the image\n",
    "    cv2.rectangle(img_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img_cv, cls, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_cv)\n",
    "plt.axis('off')\n",
    "plt.show() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
